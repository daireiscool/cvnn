{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_regression\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class BasicActivation():\n",
    "    \"\"\"\n",
    "    A basic activation function.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        ::param input: (float) A single value \n",
    "        ::output: (float)\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def activate(self, inputs):\n",
    "        \"\"\"\n",
    "        Activation function.\n",
    "        \n",
    "        ::param inputs: (list|array)\n",
    "        \"\"\"\n",
    "        return inputs\n",
    "    \n",
    "    def diff(self, inputs):\n",
    "        \"\"\"\n",
    "        Differential of the activation function.\n",
    "        \n",
    "        ::param inputs: (list|array)\n",
    "        \"\"\"\n",
    "        return 1\n",
    "\n",
    "\n",
    "class NN():\n",
    "    \"\"\"\n",
    "    Class implication of a generic Neural Network whose\n",
    "        weights can be Real, Complex or Other.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        input_size: int = 2,\n",
    "        output_size: int = 1,\n",
    "        activation_functions: list = [],\n",
    "        layers: list = [8,],\n",
    "        verbose: bool = True,\n",
    "        random_seed: int = 0,\n",
    "        ):\n",
    "        \"\"\"\n",
    "        Initialisation of the NN class.\n",
    "        \n",
    "        The inputs are:\n",
    "        ::param input_size: (int)\n",
    "        ::param output_size: (int)\n",
    "        ::param activation_functions: (list[functions]) Activation for each layer\n",
    "        ::param layers: (list[int]) List of neurons per layer.\n",
    "        ::param verbose: (bool) To print outputs/logs.\n",
    "        ::param random_seed: (int) Random seed.\n",
    "        \"\"\"\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.activation_functions = activation_functions\n",
    "        self.layers = layers\n",
    "        self.verbose = verbose\n",
    "        random.seed(random_seed)\n",
    "        self.random_seed = random_seed\n",
    "        \n",
    "        self.weights = self._initialise_weights()\n",
    "\n",
    "\n",
    "    def _initialise_weights(self):\n",
    "        \"\"\"\n",
    "        Function to initialise weights for the layers\n",
    "            with random weights.\n",
    "        \n",
    "        ::output: (list[arrays])\n",
    "        \"\"\"\n",
    "        weights = []\n",
    "        for num, layer in enumerate(self.layers + [self.output_size]):\n",
    "            if num == 0:\n",
    "                weights = weights + [\n",
    "                    np.array([[random.uniform(-10, 10) for val in range(self.input_size+1)]\n",
    "                              for r in range(layer)])\n",
    "                ]    \n",
    "            else:\n",
    "                weights = weights + [\n",
    "                    np.array([[random.uniform(-10, 10) for val in range(self.layers[num-1]+1)]\n",
    "                              for r in range(layer)])\n",
    "                ]    \n",
    "        return weights            \n",
    "\n",
    "\n",
    "    def _log(self, args):\n",
    "        \"\"\"\n",
    "        Simple print of a log function.\n",
    "        \"\"\"\n",
    "        if self.verbose:\n",
    "            print(*args)\n",
    "\n",
    "\n",
    "    def _mse(self, y_pred, y):\n",
    "        \"\"\"\n",
    "        Mean Squared Error.\n",
    "        \n",
    "        ::param y_pred: (array)\n",
    "        ::param y: (array)\n",
    "        \"\"\"\n",
    "        return sum((y*1 - y_pred)**2)/len(y)\n",
    "        \n",
    "        \n",
    "    def fit(\n",
    "        self,\n",
    "        X_train,\n",
    "        y_train,\n",
    "        loss: classmethod,\n",
    "        backpropogation_function: function,\n",
    "        validation_data: list = (),\n",
    "        validation_size: float = 0,\n",
    "        alpha: float= 1e3,\n",
    "        early_stopping: float = 1e-5,\n",
    "        epoch: int = 100,\n",
    "        n_iter: int = 10_000\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Function to train a Neural Network on inputed data.\n",
    "        \n",
    "        ::param X_train: (pandas dataframe|ndarray)\n",
    "        ::param y_train: (pandas series|array)\n",
    "        ::param loss: (class)\n",
    "        ::param backpropogation_function: (function)\n",
    "        ::param validation_data: (list[ndarray, array]) Data to validate the model on\n",
    "        ::param validation_size: (float) Splits the training data if > 0 and validation_data is empty\n",
    "        ::param alpha: (float) Learning step size\n",
    "        ::param early_stopping: (float) Stops training if difference is less than value\n",
    "        ::param epoch: (int) Epoch size for training\n",
    "        ::param n_iter: (int) Max number of training iterations\n",
    "        \"\"\"\n",
    "        \n",
    "        if validation_data | validation_size:\n",
    "            self.validation = True\n",
    "            self._log(\"Using Validation Data\")\n",
    "            if validation_data:\n",
    "                X_train, y_train = shuffle(X_train, y_train, self.random_seed)\n",
    "                X_val, y_val = shuffle(\n",
    "                    *validation_data, self.random_seed)\n",
    "            else:\n",
    "                X_train, y_train, X_val, y_val = train_test_split(\n",
    "                    X_train, y_train, test_size=validation_size, random_state=self.random_seed)\n",
    "        else:\n",
    "            self.validation = False        \n",
    "        \n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.loss = loss\n",
    "        self.backpropogation_function = backpropogation_function\n",
    "        self.X_val = X_val\n",
    "        self.y_val = y_val\n",
    "        self.alpha = alpha\n",
    "        self.early_stopping = early_stopping\n",
    "        self.epoch = epoch\n",
    "        self.n_iter = n_iter\n",
    "\n",
    "        self.loss_train = np.array([])\n",
    "        self.loss_val = np.array([])\n",
    "\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Function to predict based on given weights.\n",
    "\n",
    "        ::param X: (pandas dataframe|ndarray) Data to evaluate/ predict model against\n",
    "        \"\"\"\n",
    "        y_pred = np.array([])\n",
    "\n",
    "        for i in X:\n",
    "            z = i\n",
    "            for num, weight in enumerate(self.weights):\n",
    "                z = np.append(z, 1)\n",
    "                z = z*weight\n",
    "                z = self.activation_functions[num]().activate(np.sum(z, axis = 1))\n",
    "            y_pred  = np.append(y_pred, z)\n",
    "        \n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datasets\n",
    "X, y = make_regression(\n",
    "    n_samples = 200,\n",
    "    n_features = 2,\n",
    "    n_informative = 2,\n",
    "    n_targets = 1,#\n",
    "    #bias = 0.1,\n",
    "    noise=0,\n",
    "    random_state=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "self = NN(input_size = X.shape[1], output_size = 1, layers = [8, 8, 8], activation_functions = [BasicActivation]*4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Genetical Algorithims to train weights\n",
    "import pygad\n",
    "\n",
    "# Get correct number of parameters\n",
    "parameters = 0\n",
    "for weight in self.weights:\n",
    "    parameters += np.product(weight.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def array2ndarray(parameters, weights):\n",
    "    \"\"\"\n",
    "    Function to convert a list to the weights of of the neural network.\n",
    "    \n",
    "    ::param parameters: (array)\n",
    "    ::output: (list[array])\n",
    "    \"\"\"\n",
    "    output = []\n",
    "    for weight in weights:\n",
    "        size = np.product(weight.shape)\n",
    "        \n",
    "        output += [np.reshape(parameters[:size], weight.shape)]\n",
    "        parameters = parameters[size:]\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(y_pred, y):\n",
    "    \"\"\"\n",
    "    Mean Squared Error.\n",
    "\n",
    "    ::param y_pred: (array)\n",
    "    ::param y: (array)\n",
    "    \"\"\"\n",
    "    return sum((y*1 - y_pred)**2)/len(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitness_func(solution, solution_idx):\n",
    "    self.weights = array2ndarray(solution, self.weights)\n",
    "    y_pred = self.predict(X)\n",
    "    return -1*mse(y_pred, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "177"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitness_function = fitness_func\n",
    "\n",
    "num_generations = 100\n",
    "num_parents_mating = 10\n",
    "gene_type=float\n",
    "\n",
    "sol_per_pop = 100\n",
    "num_genes = int(parameters)\n",
    "\n",
    "init_range_low = -10\n",
    "init_range_high = 10\n",
    "\n",
    "parent_selection_type = \"sss\"\n",
    "keep_parents = 2\n",
    "\n",
    "crossover_type = \"single_point\"\n",
    "\n",
    "mutation_type = \"random\"\n",
    "mutation_percent_genes = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_fitness(ga_instance, population_fitness):\n",
    "    print(f\"{ga_instance} = Best Loss: {max(population_fitness)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ga_instance = pygad.GA(num_generations=num_generations,\n",
    "                       num_parents_mating=num_parents_mating,\n",
    "                       fitness_func=fitness_function,\n",
    "                       sol_per_pop=sol_per_pop,\n",
    "                       gene_type=gene_type,\n",
    "                       num_genes=num_genes,\n",
    "                       init_range_low=init_range_low,\n",
    "                       init_range_high=init_range_high,\n",
    "                       parent_selection_type=parent_selection_type,\n",
    "                       keep_parents=keep_parents,\n",
    "                       parallel_processing=128,\n",
    "                       crossover_type=crossover_type,\n",
    "                       mutation_type=mutation_type,\n",
    "                       on_fitness = on_fitness,\n",
    "                       mutation_percent_genes=mutation_percent_genes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pygad.pygad.GA object at 0x000001BF4B7A0370> = Best Loss: -165106863.97269538\n",
      "<pygad.pygad.GA object at 0x000001BF4B7A0370> = Best Loss: -165106863.97269538\n",
      "<pygad.pygad.GA object at 0x000001BF4B7A0370> = Best Loss: -165106863.97269538\n",
      "<pygad.pygad.GA object at 0x000001BF4B7A0370> = Best Loss: -85852482.42177433\n",
      "<pygad.pygad.GA object at 0x000001BF4B7A0370> = Best Loss: -85119398.41476348\n",
      "<pygad.pygad.GA object at 0x000001BF4B7A0370> = Best Loss: -85119398.41476348\n",
      "<pygad.pygad.GA object at 0x000001BF4B7A0370> = Best Loss: -73239335.38026932\n",
      "<pygad.pygad.GA object at 0x000001BF4B7A0370> = Best Loss: -73239335.38026932\n",
      "<pygad.pygad.GA object at 0x000001BF4B7A0370> = Best Loss: -73239335.38026932\n",
      "<pygad.pygad.GA object at 0x000001BF4B7A0370> = Best Loss: -73239335.38026932\n",
      "<pygad.pygad.GA object at 0x000001BF4B7A0370> = Best Loss: -54374492.12266657\n",
      "<pygad.pygad.GA object at 0x000001BF4B7A0370> = Best Loss: -54374492.12266657\n",
      "<pygad.pygad.GA object at 0x000001BF4B7A0370> = Best Loss: -49016371.75601168\n",
      "<pygad.pygad.GA object at 0x000001BF4B7A0370> = Best Loss: -37603193.782047816\n",
      "<pygad.pygad.GA object at 0x000001BF4B7A0370> = Best Loss: -37603193.782047816\n",
      "<pygad.pygad.GA object at 0x000001BF4B7A0370> = Best Loss: -19783681.812943373\n",
      "<pygad.pygad.GA object at 0x000001BF4B7A0370> = Best Loss: -19783681.812943373\n",
      "<pygad.pygad.GA object at 0x000001BF4B7A0370> = Best Loss: -14065884.16278863\n",
      "<pygad.pygad.GA object at 0x000001BF4B7A0370> = Best Loss: -14022289.930734828\n",
      "<pygad.pygad.GA object at 0x000001BF4B7A0370> = Best Loss: -7206502.054544316\n",
      "<pygad.pygad.GA object at 0x000001BF4B7A0370> = Best Loss: -3690089.459986242\n",
      "<pygad.pygad.GA object at 0x000001BF4B7A0370> = Best Loss: -2109419.244929653\n",
      "<pygad.pygad.GA object at 0x000001BF4B7A0370> = Best Loss: -2109419.244929653\n",
      "<pygad.pygad.GA object at 0x000001BF4B7A0370> = Best Loss: -2109419.244929653\n",
      "<pygad.pygad.GA object at 0x000001BF4B7A0370> = Best Loss: -1177402.3547007442\n",
      "<pygad.pygad.GA object at 0x000001BF4B7A0370> = Best Loss: -1177402.3547007442\n",
      "<pygad.pygad.GA object at 0x000001BF4B7A0370> = Best Loss: -1177402.3547007442\n",
      "<pygad.pygad.GA object at 0x000001BF4B7A0370> = Best Loss: -1177402.3547007442\n",
      "<pygad.pygad.GA object at 0x000001BF4B7A0370> = Best Loss: -1177402.3547007442\n",
      "<pygad.pygad.GA object at 0x000001BF4B7A0370> = Best Loss: -1177402.3547007442\n",
      "<pygad.pygad.GA object at 0x000001BF4B7A0370> = Best Loss: -1177402.3547007442\n",
      "<pygad.pygad.GA object at 0x000001BF4B7A0370> = Best Loss: -1177402.3547007442\n",
      "<pygad.pygad.GA object at 0x000001BF4B7A0370> = Best Loss: -1177402.3547007442\n",
      "<pygad.pygad.GA object at 0x000001BF4B7A0370> = Best Loss: -1177402.3547007442\n",
      "<pygad.pygad.GA object at 0x000001BF4B7A0370> = Best Loss: -1177402.3547007442\n",
      "<pygad.pygad.GA object at 0x000001BF4B7A0370> = Best Loss: -1177402.3547007442\n",
      "<pygad.pygad.GA object at 0x000001BF4B7A0370> = Best Loss: -646270.3966792916\n",
      "<pygad.pygad.GA object at 0x000001BF4B7A0370> = Best Loss: -646270.3966792916\n",
      "<pygad.pygad.GA object at 0x000001BF4B7A0370> = Best Loss: -646270.3966792916\n",
      "<pygad.pygad.GA object at 0x000001BF4B7A0370> = Best Loss: -646270.3966792916\n",
      "<pygad.pygad.GA object at 0x000001BF4B7A0370> = Best Loss: -646270.3966792916\n",
      "<pygad.pygad.GA object at 0x000001BF4B7A0370> = Best Loss: -646270.3966792916\n",
      "<pygad.pygad.GA object at 0x000001BF4B7A0370> = Best Loss: -646270.3966792916\n",
      "<pygad.pygad.GA object at 0x000001BF4B7A0370> = Best Loss: -646270.3966792916\n",
      "<pygad.pygad.GA object at 0x000001BF4B7A0370> = Best Loss: -646270.3966792916\n",
      "<pygad.pygad.GA object at 0x000001BF4B7A0370> = Best Loss: -646270.3966792916\n",
      "<pygad.pygad.GA object at 0x000001BF4B7A0370> = Best Loss: -646270.3966792916\n",
      "<pygad.pygad.GA object at 0x000001BF4B7A0370> = Best Loss: -646270.3966792916\n",
      "<pygad.pygad.GA object at 0x000001BF4B7A0370> = Best Loss: -646270.3966792916\n",
      "<pygad.pygad.GA object at 0x000001BF4B7A0370> = Best Loss: -646270.3966792916\n",
      "<pygad.pygad.GA object at 0x000001BF4B7A0370> = Best Loss: -646270.3966792916\n",
      "<pygad.pygad.GA object at 0x000001BF4B7A0370> = Best Loss: -646270.3966792916\n",
      "<pygad.pygad.GA object at 0x000001BF4B7A0370> = Best Loss: -424237.56438088027\n",
      "<pygad.pygad.GA object at 0x000001BF4B7A0370> = Best Loss: -424237.56438088027\n",
      "<pygad.pygad.GA object at 0x000001BF4B7A0370> = Best Loss: -424237.56438088027\n",
      "<pygad.pygad.GA object at 0x000001BF4B7A0370> = Best Loss: -424237.56438088027\n",
      "<pygad.pygad.GA object at 0x000001BF4B7A0370> = Best Loss: -66917.68680086322\n",
      "<pygad.pygad.GA object at 0x000001BF4B7A0370> = Best Loss: -66917.68680086322\n",
      "<pygad.pygad.GA object at 0x000001BF4B7A0370> = Best Loss: -66917.68680086322\n",
      "<pygad.pygad.GA object at 0x000001BF4B7A0370> = Best Loss: -66917.68680086322\n",
      "<pygad.pygad.GA object at 0x000001BF4B7A0370> = Best Loss: -66917.68680086322\n",
      "<pygad.pygad.GA object at 0x000001BF4B7A0370> = Best Loss: -42435.47382816752\n",
      "<pygad.pygad.GA object at 0x000001BF4B7A0370> = Best Loss: -42435.47382816752\n",
      "<pygad.pygad.GA object at 0x000001BF4B7A0370> = Best Loss: -42435.47382816752\n",
      "<pygad.pygad.GA object at 0x000001BF4B7A0370> = Best Loss: -42435.47382816752\n",
      "<pygad.pygad.GA object at 0x000001BF4B7A0370> = Best Loss: -42435.47382816752\n",
      "<pygad.pygad.GA object at 0x000001BF4B7A0370> = Best Loss: -42435.47382816752\n",
      "<pygad.pygad.GA object at 0x000001BF4B7A0370> = Best Loss: -42435.47382816752\n",
      "<pygad.pygad.GA object at 0x000001BF4B7A0370> = Best Loss: -42435.47382816752\n",
      "<pygad.pygad.GA object at 0x000001BF4B7A0370> = Best Loss: -42435.47382816752\n",
      "<pygad.pygad.GA object at 0x000001BF4B7A0370> = Best Loss: -42435.47382816752\n",
      "<pygad.pygad.GA object at 0x000001BF4B7A0370> = Best Loss: -42435.47382816752\n",
      "<pygad.pygad.GA object at 0x000001BF4B7A0370> = Best Loss: -42435.47382816752\n",
      "<pygad.pygad.GA object at 0x000001BF4B7A0370> = Best Loss: -42435.47382816752\n",
      "<pygad.pygad.GA object at 0x000001BF4B7A0370> = Best Loss: -42435.47382816752\n",
      "<pygad.pygad.GA object at 0x000001BF4B7A0370> = Best Loss: -42435.47382816752\n",
      "<pygad.pygad.GA object at 0x000001BF4B7A0370> = Best Loss: -42435.47382816752\n",
      "<pygad.pygad.GA object at 0x000001BF4B7A0370> = Best Loss: -42435.47382816752\n",
      "<pygad.pygad.GA object at 0x000001BF4B7A0370> = Best Loss: -42435.47382816752\n",
      "<pygad.pygad.GA object at 0x000001BF4B7A0370> = Best Loss: -42435.47382816752\n",
      "<pygad.pygad.GA object at 0x000001BF4B7A0370> = Best Loss: -7104.787947742992\n",
      "<pygad.pygad.GA object at 0x000001BF4B7A0370> = Best Loss: -7104.787947742992\n",
      "<pygad.pygad.GA object at 0x000001BF4B7A0370> = Best Loss: -7104.787947742992\n",
      "<pygad.pygad.GA object at 0x000001BF4B7A0370> = Best Loss: -7104.787947742992\n",
      "<pygad.pygad.GA object at 0x000001BF4B7A0370> = Best Loss: -7104.787947742992\n",
      "<pygad.pygad.GA object at 0x000001BF4B7A0370> = Best Loss: -7104.787947742992\n",
      "<pygad.pygad.GA object at 0x000001BF4B7A0370> = Best Loss: -7104.787947742992\n",
      "<pygad.pygad.GA object at 0x000001BF4B7A0370> = Best Loss: -7104.787947742992\n",
      "<pygad.pygad.GA object at 0x000001BF4B7A0370> = Best Loss: -7104.787947742992\n",
      "<pygad.pygad.GA object at 0x000001BF4B7A0370> = Best Loss: -7104.787947742992\n",
      "<pygad.pygad.GA object at 0x000001BF4B7A0370> = Best Loss: -7104.787947742992\n",
      "<pygad.pygad.GA object at 0x000001BF4B7A0370> = Best Loss: -7104.787947742992\n",
      "<pygad.pygad.GA object at 0x000001BF4B7A0370> = Best Loss: -7104.787947742992\n",
      "<pygad.pygad.GA object at 0x000001BF4B7A0370> = Best Loss: -7104.787947742992\n",
      "<pygad.pygad.GA object at 0x000001BF4B7A0370> = Best Loss: -7104.787947742992\n",
      "<pygad.pygad.GA object at 0x000001BF4B7A0370> = Best Loss: -7104.787947742992\n",
      "<pygad.pygad.GA object at 0x000001BF4B7A0370> = Best Loss: -7104.787947742992\n",
      "<pygad.pygad.GA object at 0x000001BF4B7A0370> = Best Loss: -7104.787947742992\n",
      "<pygad.pygad.GA object at 0x000001BF4B7A0370> = Best Loss: -7104.787947742992\n",
      "<pygad.pygad.GA object at 0x000001BF4B7A0370> = Best Loss: -7104.787947742992\n"
     ]
    }
   ],
   "source": [
    "ga_instance.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitness value of the best solution = -7104.787947742992\n",
      "Generic Prediction : -751016.6443721614\n"
     ]
    }
   ],
   "source": [
    "solution, solution_fitness, solution_idx = ga_instance.best_solution()\n",
    "#print(\"Parameters of the best solution : {solution}\".format(solution=solution))\n",
    "print(\"Fitness value of the best solution = {solution_fitness}\".format(solution_fitness=solution_fitness))\n",
    "\n",
    "print(f\"Generic Prediction : {fitness_func([1]*int(parameters), None)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.weights = array2ndarray(solution, self.weights)\n",
    "y_pred = self.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1bf4b7ca8e0>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(x = y, y = y_pred)\n",
    "plt.plot([min(y), max(y)], [min(y), max(y)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "d75af684bc2d43b24852edad0f68f7cdb57df0ef378bc27b5f5cba476e78e901"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
